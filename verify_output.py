#!/usr/bin/env python3
"""
Verification script for MIAOU
This script:
1. Reproduces the calculations from the main_test_output.F90 program
2. Reads the namelist configuration to determine which variables to write
3. Compares calculated values with the content of generated NetCDF files

Using xarray for improved compatibility across platforms.
"""

import os
import re
import numpy as np
import xarray as xr
import matplotlib.pyplot as plt
from datetime import datetime

# Simulation parameters (identical to those in main_test_output.F90)
NX = 10
NY = 8 
NZ = 5
NT = 10
DT = 1800.0  # seconds - time step

def parse_namelist(filename="output_config.nml"):
    """Parse the namelist file to extract output configuration"""
    
    config = {
        'global': {},
        'variables': []
    }
    
    if not os.path.exists(filename):
        print(f"ERROR: File {filename} not found!")
        return config
    
    # Read the file
    with open(filename, 'r') as f:
        content = f.read()
    
    # Extract global prefixes
    global_match = re.search(r'&output_global(.*?)/', content, re.DOTALL)
    if global_match:
        global_section = global_match.group(1)
        
        his_match = re.search(r'his_prefix\s*=\s*"([^"]*)"', global_section)
        if his_match:
            config['global']['his_prefix'] = his_match.group(1)
        
        avg_match = re.search(r'avg_prefix\s*=\s*"([^"]*)"', global_section)
        if avg_match:
            config['global']['avg_prefix'] = avg_match.group(1)
        
        rst_match = re.search(r'rst_prefix\s*=\s*"([^"]*)"', global_section)
        if rst_match:
            config['global']['rst_prefix'] = rst_match.group(1)
    
    # Extract variables
    dyn_match = re.search(r'&output_dyn(.*?)/', content, re.DOTALL)
    if dyn_match:
        dyn_section = dyn_match.group(1)
        
        # Find all dyn_vars lines
        var_lines = re.findall(r'dyn_vars\(\d+\)\s*=\s*"([^"]*)",\s*(\.true\.|\.false\.),\s*(\.true\.|\.false\.),\s*(\.true\.|\.false\.),\s*"([^"]*)",\s*([^,]*),\s*([^,]*),\s*([^.,]*)\.', dyn_section)
        
        for var_line in var_lines:
            name, wrt, avg, rst, prefix, freq_his, freq_avg, freq_rst = var_line
            config['variables'].append({
                'name': name,
                'wrt': wrt == '.true.',
                'avg': avg == '.true.',
                'rst': rst == '.true.',
                'prefix': prefix,
                'freq_his': float(freq_his),
                'freq_avg': float(freq_avg),
                'freq_rst': float(freq_rst)
            })
    
    return config

def simulate_calculations():
    """Reproduces the analytical calculations performed in main_test_output.F90"""
    
    # Initialize arrays
    zeta = np.zeros((NX, NY))
    temp = np.zeros((NX, NY, NZ))
    u = np.zeros((NX, NY))
    v = np.zeros((NX, NY))
    
    # Array to store results at each time step
    results = {
        'time': [],
        'zeta': [],
        'temp': [],
        'u': [],
        'v': []
    }
    
    # Time loop
    for t in range(1, NT+1):
        # Time in seconds
        current_time = (t - 1) * DT
        
        # Update values (as in main_test_output.F90)
        zeta += 0.1 * t
        temp[:, :, 0] += 0.2 * t
        u[:] = t
        v[:] = t * 0.5
        
        # Store results
        results['time'].append(current_time)
        results['zeta'].append(zeta.copy())
        results['temp'].append(temp[:, :, 0].copy())
        results['u'].append(u.copy())
        results['v'].append(v.copy())
    
    return results

def find_netcdf_files():
    """Finds all NetCDF files generated by MIAOU"""
    
    nc_files = []
    for filename in os.listdir('.'):
        if filename.endswith('.nc'):
            nc_files.append(filename)
    
    return nc_files

def check_file_content(filename, config, calc_results):
    """Checks the content of a NetCDF file against analytical calculations"""
    
    print(f"\nVerifying file: {filename}")
    
    # Determine file type (his, avg, rst)
    file_type = None
    var_prefix = None
    freq = None
    
    if "_his_" in filename:
        file_type = "his"
    elif "_avg_" in filename:
        file_type = "avg"
    elif "_rst_" in filename:
        file_type = "rst"
    
    # Extract frequency from filename
    freq_match = re.search(r'_(\d+)s\.nc$', filename)
    if freq_match:
        freq = int(freq_match.group(1))
    
    # Determine if this is a file with specific prefix
    for var in config['variables']:
        if var['prefix'] and filename.startswith(var['prefix']):
            var_prefix = var['prefix']
            break
    
    # Open NetCDF file using xarray
    try:
        # Open with decode_times=False to keep time as numbers
        nc = xr.open_dataset(filename, decode_times=False)
    except Exception as e:
        print(f"ERROR: Cannot open {filename}: {e}")
        return
    
    # Display general information
    print(f"  Type: {file_type}, Frequency: {freq}s, Prefix: {var_prefix or 'global'}")
    print(f"  Dimensions: {list(nc.dims.keys())}")
    print(f"  Variables: {list(nc.data_vars.keys())}")
    
    # Get time values
    if 'time' in nc.coords:
        time_points = nc.time.values
        # Convert to float if needed (in case it's still in a different format)
        time_points = time_points.astype(float)
    else:
        print("  WARNING: No time dimension found in file")
        nc.close()
        return
    
    # Check each variable in the file
    for var_name in nc.data_vars:
        print(f"\n  Checking variable: {var_name}")
        
        # Find configuration information for this variable
        var_config = None
        for var in config['variables']:
            if var['name'] == var_name:
                var_config = var
                break
        
        if var_config is None:
            print(f"    WARNING: Variable {var_name} not found in configuration!")
            continue
        
        # Check if this variable should be in this file
        should_be_in_file = False
        
        if file_type == "his" and var_config['wrt']:
            if var_config['freq_his'] > 0 and abs(var_config['freq_his'] - freq) < 1e-5:
                should_be_in_file = True
        elif file_type == "avg" and var_config['avg']:
            if var_config['freq_avg'] > 0 and abs(var_config['freq_avg'] - freq) < 1e-5:
                should_be_in_file = True
        elif file_type == "rst" and var_config['rst']:
            if var_config['freq_rst'] > 0 and abs(var_config['freq_rst'] - freq) < 1e-5:
                should_be_in_file = True
        
        # Check prefix
        if var_prefix and var_config['prefix'] != var_prefix:
            should_be_in_file = False
        elif not var_prefix and var_config['prefix']:
            should_be_in_file = False
        
        if not should_be_in_file:
            print(f"    ERROR: Variable {var_name} should NOT be in this file!")
            continue
        
        # Read data
        var_data = nc[var_name].values
        
        # Compare with analytical calculations
        for i, time_value in enumerate(time_points):
            # Now time_value should be a float we can compare directly
            time_idx = np.argmin(np.abs(np.array(calc_results['time']) - time_value))
            
            # Calculate difference
            # With:
            if var_name == 'zeta':
                expected = calc_results['zeta'][time_idx].transpose()  # Transpose to match file format
            elif var_name == 'temp':
                expected = calc_results['temp'][time_idx].transpose()  # Transpose to match file format
            elif var_name == 'u':
                expected = calc_results['u'][time_idx].transpose()  # Transpose to match file format
            elif var_name == 'v':
                expected = calc_results['v'][time_idx].transpose()  # Transpose to match file format
            else:
                print(f"    WARNING: No analytical value for {var_name}")
                continue
            
            actual = var_data[i]
            
            # For averages, calculate expected average value
            if file_type == "avg":
                # Find time steps that contribute to this average
                steps_in_avg = 0
                sum_values = np.zeros_like(expected)
                
                for j in range(time_idx + 1):
                    if j == 0 or (calc_results['time'][j] % freq) < 1e-5:
                        steps_in_avg += 1
                        if var_name == 'zeta':
                            sum_values += calc_results['zeta'][j].transpose()  # Transpose to match file format
                        elif var_name == 'temp':
                            sum_values += calc_results['temp'][j].transpose()  # Transpose to match file format
                        elif var_name == 'u':
                            sum_values += calc_results['u'][j].transpose()  # Transpose to match file format
                        elif var_name == 'v':
                            sum_values += calc_results['v'][j].transpose()  # Transpose to match file format
                
                if steps_in_avg > 0:
                    expected = sum_values / steps_in_avg
            
            # Calculate relative error
            if np.all(np.abs(expected) < 1e-10):
                rel_error = np.abs(actual - expected)
            else:
                rel_error = np.abs((actual - expected) / expected)
            
            max_error = np.max(rel_error)
            
            if max_error > 1e-5:
                print(f"    ERROR at t={time_value}: Max error = {max_error:.6f}")
                # Display sample values for debugging
                print(f"      Expected[0,0]: {expected[0,0]}, Actual[0,0]: {actual[0,0]}")
            else:
                print(f"    OK at t={time_value}: Max error = {max_error:.6f}")
    
    nc.close()

def plot_results(filename, variable, time_index=None):
    """Creates a plot to visualize the results"""
    
    if not os.path.exists(filename):
        print(f"ERROR: File {filename} not found!")
        return
    
    try:
        # Open file with xarray, disable time decoding
        nc = xr.open_dataset(filename, decode_times=False)
    except Exception as e:
        print(f"ERROR: Cannot open {filename}: {e}")
        return
    
    if variable not in nc.data_vars:
        print(f"ERROR: Variable {variable} not found in {filename}!")
        nc.close()
        return
    
    # Get data and time
    data = nc[variable].values
    if 'time' in nc.coords:
        time = nc.time.values.astype(float)  # Ensure time is numeric
    else:
        time = np.arange(data.shape[0])
    
    if time_index is None and len(time) > 0:
        time_index = len(time) - 1  # Last time step by default
    
    plt.figure(figsize=(10, 8))
    
    if time_index is not None and time_index < len(time):
        plt.pcolormesh(data[time_index], shading='auto')
        
        # Get units from xarray if available
        units = nc[variable].attrs.get('units', '')
        plt.colorbar(label=f'{variable} ({units})')
        
        # Format time value for title
        time_str = f"{float(time[time_index]):.1f}s"
            
        plt.title(f'{variable} at t={time_str} in {os.path.basename(filename)}')
    else:
        # Plot time evolution at a central point
        mid_x = data.shape[1] // 2
        mid_y = data.shape[2] // 2 if len(data.shape) > 2 else data.shape[1] // 2
        
        if len(data.shape) > 2:
            plt.plot(time, data[:, mid_x, mid_y])
        else:
            plt.plot(time, data[:, mid_x])
            
        plt.xlabel('Time (s)')
        plt.ylabel(f'{variable} ({nc[variable].attrs.get("units", "")})')
        plt.title(f'Evolution of {variable} at central point in {os.path.basename(filename)}')
    
    plt.tight_layout()
    
    # Create folder for plots if it doesn't exist
    if not os.path.exists('plots'):
        os.makedirs('plots')
    
    # Generate unique filename with timestamp
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    plot_filename = f'plots/{variable}_{os.path.basename(filename)}_{timestamp}.png'
    
    plt.savefig(plot_filename)
    print(f"Plot saved: {plot_filename}")
    plt.close()
    
    nc.close()

def main():
    print("Verification script for MIAOU")
    print("================================")
    
    # Step 1: Analyze configuration
    print("\nAnalyzing configuration...")
    config = parse_namelist()
    
    if not config['variables']:
        print("ERROR: No variables found in configuration!")
        return
    
    print(f"Global prefixes: {config['global']}")
    print(f"Configured variables: {[var['name'] for var in config['variables']]}")
    
    # Step 2: Reproduce calculations
    print("\nReproducing analytical calculations...")
    calc_results = simulate_calculations()
    print(f"Calculations performed for {len(calc_results['time'])} time steps")
    
    # Step 3: Find NetCDF files
    print("\nSearching for NetCDF files...")
    nc_files = find_netcdf_files()
    
    if not nc_files:
        print("ERROR: No NetCDF files found!")
        return
    
    print(f"Files found: {nc_files}")
    
    # Step 4: Check each file
    for filename in nc_files:
        check_file_content(filename, config, calc_results)
    
    # Step 5: Create some plots
#    print("\nCreating plots...")
#    for filename in nc_files:
#        for var in ['zeta', 'temp', 'u', 'v']:
#            try:
#                # Quick check if variable exists in file
#                with xr.open_dataset(filename) as ds:
#                    if var in ds.data_vars:
#                        plot_results(filename, var)
#            except:
#                pass
    
    print("\nVerification complete!")

if __name__ == "__main__":
    main()